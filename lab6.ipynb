{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNklcAesUjmte3LZomdRBSA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhalidSwaid/CloudCourse/blob/main/lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Huwe5HmrWFY",
        "outputId": "8f187c98-f4e4-4c46-bbb3-772106be386e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Collecting firebase\n",
            "  Downloading firebase-4.0.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firebase) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firebase) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->firebase) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firebase) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firebase) (2024.2.2)\n",
            "Installing collected packages: firebase\n",
            "Successfully installed firebase-4.0.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install requests beautifulsoup4\n",
        "!pip install firebase"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from firebase import firebase"
      ],
      "metadata": {
        "id": "vShzZ6UXrbgU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fbConn = firebase.FirebaseApplication('https://lab6-87d9f-default-rtdb.firebaseio.com/',None)"
      ],
      "metadata": {
        "id": "te84RUtErjeU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def fetch_page(url):\n",
        "  response = requests.get(url)\n",
        "  if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    return soup\n",
        "  else:\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "yc3meuwcrxjT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def index_words(soup):\n",
        "    index = {}\n",
        "    words = re.findall(r'\\w+', soup.get_text())\n",
        "    for word in words:\n",
        "        word = word.lower()\n",
        "        if word in index:\n",
        "            index[word] += 1\n",
        "        else:\n",
        "            index[word] = 1\n",
        "    #print(format_json(index))\n",
        "    return index"
      ],
      "metadata": {
        "id": "aYjcWKtarzyd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(index):\n",
        "  stop_words = {'a', 'an', 'the', 'and', 'or','in', 'on', 'at'}\n",
        "  for stop_word in stop_words:\n",
        "      if stop_word in index:\n",
        "            del index[stop_word]\n",
        "  return index"
      ],
      "metadata": {
        "id": "721EH3Fgr2ji"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "def apply_stemming(index):\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_index = {}\n",
        "    for word, count in index.items():\n",
        "        stemmed_word = stemmer.stem(word)\n",
        "        if stemmed_word in stemmed_index:\n",
        "            stemmed_index[stemmed_word] += count\n",
        "        else:\n",
        "            stemmed_index[stemmed_word] = count\n",
        "    return stemmed_index"
      ],
      "metadata": {
        "id": "P_DjuoO3r4c_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query, index):\n",
        "    query_words = re.findall(r'\\w+', query.lower())\n",
        "    results = {}\n",
        "    for word in query_words:\n",
        "        if word in index:\n",
        "            results[word] = index[word]\n",
        "    return results"
      ],
      "metadata": {
        "id": "z4SGKyeYr6eE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_engine(url, query):\n",
        "    soup = fetch_page(url)\n",
        "    if soup is None:\n",
        "        return None\n",
        "    index = index_words(soup)\n",
        "    index = remove_stop_words(index)\n",
        "    index = apply_stemming(index)\n",
        "    results = search(query, index)\n",
        "    return results"
      ],
      "metadata": {
        "id": "0AXBIbBvr8CD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urlparse, urljoin\n",
        "from collections import deque\n",
        "\n",
        "# Function to extract links from a webpage\n",
        "def extract_links(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    links = []\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        links.append(link['href'])\n",
        "    return links\n",
        "\n",
        "# Function to check if links are from the same domain\n",
        "def check_same_domain(base_url, links):\n",
        "    base_domain = urlparse(base_url).netloc\n",
        "    same_domain_links = []\n",
        "    for link in links:\n",
        "        parsed_link = urlparse(link)\n",
        "        if parsed_link.netloc == base_domain or parsed_link.netloc == '':\n",
        "            same_domain_links.append(link)\n",
        "    return same_domain_links\n",
        "\n",
        "def is_same_domain(base_url, url):\n",
        "    base_domain = urlparse(base_url).netloc\n",
        "    link_domain = urlparse(url).netloc\n",
        "    return base_domain == link_domain"
      ],
      "metadata": {
        "id": "_Vdj3QXgr9T-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_page_title(url):\n",
        "    soup = fetch_page(url)\n",
        "    if soup:\n",
        "        title_tag = soup.find('title')\n",
        "        if title_tag:\n",
        "            return title_tag.get_text()\n",
        "    return None"
      ],
      "metadata": {
        "id": "QnAdj7MOsAOr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def save_and_hash_url(url_to_hash):\n",
        "  # Hash the URL using MD5 hashing algorithm\n",
        "  hashed_url = hashlib.md5(url_to_hash.encode()).hexdigest()\n",
        "\n",
        "  title = fetch_page_title(url_to_hash)\n",
        "  data_to_upload = {\n",
        "    'url': url_to_hash,\n",
        "    'title': title\n",
        "  }\n",
        "  result = fbConn.put_async('/pages', hashed_url,data=data_to_upload)\n",
        "  return hashed_url"
      ],
      "metadata": {
        "id": "cWROOtAGsBzw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import urllib.parse\n",
        "\n",
        "def search_words(url,query_words):\n",
        "  hashed_url = save_and_hash_url(url)\n",
        "  #print(hashed_url)\n",
        "  for query in query_words:\n",
        "    result = search_engine(url, query)\n",
        "    if result == {}:\n",
        "      continue\n",
        "    #print(result,\" ---- \",result[query])\n",
        "    #data_to_upload ={\n",
        "    #    'link': url,\n",
        "    #    'count': result[query]\n",
        "    #}\n",
        "    data_to_upload = {\n",
        "        'count': result[query]\n",
        "    }\n",
        "    result = fbConn.put_async('/index/' + query,hashed_url,data=data_to_upload)"
      ],
      "metadata": {
        "id": "ug6rJ_cHsDPc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_url = \"https://www.ibm.com/cloud\"\n",
        "queries = [\"ai\",\"public\",\"private\",\"cloud\",\"server\",\"database\"]\n",
        "#queries = [\"infrastructure\",\"Development\",\"production\",\"holdings\"]\n",
        "\n",
        "###BFS\n",
        "\n",
        "visited = set()\n",
        "# Initialize a queue with first url\n",
        "queue = deque([start_url])\n",
        "\n",
        "#get the base domain to start from\n",
        "#base_domain = urlparse(start_url).netloc\n",
        "\n",
        "# Loop until the queue is empty\n",
        "while queue:\n",
        "  #get next url to search\n",
        "  url = queue.popleft()\n",
        "  # Skip if the URL has been visited before\n",
        "  if url in visited:\n",
        "      continue\n",
        "\n",
        "  # mark visited\n",
        "  visited.add(url)\n",
        "\n",
        "  print(\"Visiting:\", url)\n",
        "  #Get all the links in this page\n",
        "  links = extract_links(url)\n",
        "  print(\"Links Extracted: \",len(links))\n",
        "\n",
        "  #searching words and saving them to firebase\n",
        "\n",
        "  search_words(url,queries)\n",
        "  # Ppocess link\n",
        "  for link in links:\n",
        "    absolute_link = urljoin(url, link)\n",
        "\n",
        "    if is_same_domain(start_url, absolute_link) and absolute_link not in visited:\n",
        "      #add link to queue\n",
        "      queue.append(absolute_link)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "7Q58EqfBsFwE",
        "outputId": "2c159577-a34e-4e11-e34e-190a77d7bd69"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visiting: https://www.ibm.com/cloud\n",
            "Links Extracted:  5\n",
            "Visiting: https://www.ibm.com/products/security-and-compliance-center\n",
            "Links Extracted:  0\n",
            "Visiting: https://www.ibm.com/products/satellite\n",
            "Links Extracted:  2\n",
            "Visiting: https://www.ibm.com/products/vmware\n",
            "Links Extracted:  2\n",
            "Visiting: https://www.ibm.com/cloud/financial-services\n",
            "Links Extracted:  0\n",
            "Visiting: https://www.ibm.com/cloud/solutions\n",
            "Links Extracted:  0\n",
            "Visiting: https://www.ibm.com/account/reg/signup?formid=urx-49524\n",
            "Links Extracted:  2\n",
            "Visiting: https://www.ibm.com/partnerplus\n",
            "Links Extracted:  2\n",
            "Visiting: https://www.ibm.com/downloads/cas/QE7BZ7A5\n",
            "Links Extracted:  0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7cabff365b77>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;31m#searching words and saving them to firebase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0msearch_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0;31m# Ppocess link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-df51600384ce>\u001b[0m in \u001b[0;36msearch_words\u001b[0;34m(url, query_words)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#print(hashed_url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-50551e827015>\u001b[0m in \u001b[0;36msearch_engine\u001b[0;34m(url, query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msearch_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-c22e120f5483>\u001b[0m in \u001b[0;36mfetch_page\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;31m# Fallback to auto-detected encoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapparent_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;31m# Decode unicode from given encoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mapparent_encoding\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapparent_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;34m\"\"\"The apparent encoding, provided by the charset_normalizer or chardet libraries.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_unicode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chardet/__init__.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(byte_str, should_rename_legacy)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mbyte_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniversalDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshould_rename_legacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshould_rename_legacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chardet/universaldetector.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMacRomanProber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mprober\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProbingState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFOUND_IT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m                     self.result = {\n\u001b[1;32m    276\u001b[0m                         \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chardet/charsetgroupprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chardet/sbcharsetprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# TODO: Make filter_international_words keep things in self.alphabet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_ascii_letters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mbyte_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_international_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mbyte_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_xml_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chardet/charsetprober.py\u001b[0m in \u001b[0;36mfilter_international_words\u001b[0;34m(buf)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# frequencies).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mlast_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlast_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlast_char\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34mb\"\\x80\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mlast_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mfiltered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}